---
title: "L1"
author: "COMPASS workflows team"
title-block-banner: true
params:
  html_outfile: "L1.html"
  DATA_ROOT: "data_TEST/"
  L1_NORMALIZE: "L1_normalize/"
  L1: "L1/"
  METADATA_ROOT: "metadata/"
  METADATA_SITE_FILES: "site_files/"
  RELEASE_README_FILES: "readme_files/"
  L1_METADATA: "L1_metadata/"
  METADATA_VARS_TABLE: "variables_metadata.csv"
  METADATA_COLUMNS_TABLE: "L1_metadata_columns.csv"
  # We use "Etc/GMT+5" rather than e.g. "America/New_York" for
  # L1_DATA_TIMEZONE because outputs should always be in STANDARD time
  # See https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
  L1_DATA_TIMEZONE: "Etc/GMT+5"
  CODE_EXAMPLES: "code_examples/"
  L1_VERSION: "???"
  L1_RELEASE_DATE: "???"
  write_plots: true
  logfile: ""
  run_parallel: false
date: now
date-format: "YYYY-MM-DD HH:mm:ssZ"
format: 
  html:
    embed-resources: true
    code-fold: true
editor: visual
---

This script

-   Reads in all the L1_normalize files

-   Compiles and writes them out into separate \<site\>\<year\>\<month\> files

-   Writes a metadata file for each folder

## Initializing

```{r init}
#| include: false

library(ggplot2)
theme_set(theme_bw())

# Warnings are not allowed here
oldwarn <- options()$warn
options(warn = 2)

source("helpers.R")
source("L1-utils.R")

# Get the column metadata file
column_md <- read.csv(file.path(params$METADATA_ROOT,
                                params$L1_METADATA,
                                params$METADATA_COLUMNS_TABLE),
                      comment.char = "#",
                      stringsAsFactors = FALSE)

# Open the fLag database (in the data, not metadata, folder)
#source("flag-database.R")
#fdb_open(params$DATA_ROOT, init = TRUE)

L1_NORMALIZE <- file.path(params$DATA_ROOT, params$L1_NORMALIZE)
dirs_to_process <- scan_folders(L1_NORMALIZE)

L1 <- file.path(params$DATA_ROOT, params$L1)
```

I see `r length(dirs_to_process)` directories to process in `r L1_NORMALIZE`.

L1 column metadata has `r nrow(column_md)` entries.

Output directory is `r L1`.

HTML outfile is "`r params$html_outfile`".

## Processing

```{r processing}
f <- function(dir_name, dirs_to_process, out_dir) {
    message(Sys.time(), " Processing ", basename(dir_name))
    d <- dirs_to_process[[dir_name]]
    message("\tIt has ", length(d), " files")
    
    # Read all files in a folder
    dat_raw <- read_csv_group(d, col_types = "cccccTdccccccccdii")
    
    message("\tTotal data: ", nrow(dat_raw), " rows, ", ncol(dat_raw), " columns")
    
    # Remove duplicate rows (e.g. from multiple datalogger downloads)
    dat <- dat_raw[!duplicated(dat_raw), ]
    message("\tRemoved ", nrow(dat_raw) - nrow(dat), " duplicate rows")
    
    # File-based summary
    smry <- data.frame(Dir = dir_name, 
                       Files = length(d), 
                       Rows = nrow(dat),
                       NA_rows = sum(is.na(dat$Value)))
    
    if(nrow(dat)) {
        site <- dat$Site[1]
        plot <- dat$Plot[1]
        
        # Check for metadata columns that are missing...
        if(!all(column_md$Column %in% colnames(dat))) {
            stop("Column metadata file ", params$METADATA_COLUMNS_TABLE,
                 " has entries not in data: ", setdiff(column_md$Column, colnames(dat)))
        }
        # ...order and remove columns not in the metadata...
        dat <- dat[column_md$Column]
        # ...and sort rows
        dat <- dat[order(dat$TIMESTAMP),]
        
        write_to_folders(dat, 
                         root_dir = out_dir, 
                         data_level = "L1",
                         site = site,
                         plot = plot,
                         version = params$L1_VERSION,
                         write_plots = params$write_plots)
    }
    rm(dat)
    return(smry)
}

# We can optionally process in parallel using all available cores
if(params$run_parallel) {
    library(parallel)
    apply_func = mclapply
    # L1 is memory-intensive, especially for the TEMPEST files, and 
    # it's possible to run out of system memory, so limit cores used
    options(mc.cores = min(6, detectCores()))
    message("Using parallel::mclapply with ", getOption("mc.cores"), " cores")
} else {
    apply_func = lapply
}

log_info("About to L1", logfile = params$logfile)
out <- apply_func(names(dirs_to_process),
                  f, 
                  dirs_to_process = dirs_to_process, 
                  out_dir = L1)

# Check whether any of the parallel jobs errored
if(params$run_parallel && "try-error" %in% sapply(out, class)) {
    stop("Error! Rerun non-parallel to diagnose")
}
out_df <- do.call("rbind", out)

if(!is.numeric(out_df$Rows)) {
    x <- which(is.na(as.numeric(out_df$Rows)))[1]
    stop("Rows is not numeric: ", out_df$Dir[x], ",",
         out_df$Files[x], ",",
         out_df$Rows[x])
}

n_obs <- format(sum(out_df$Rows), big.mark = ",")
n_na <- format(sum(out_df$NA_rows), big.mark = ",")

# Restore old warning setting
options(warn = oldwarn)
```

## Metadata

L1 metadata template directory is `r params$L1_METADATA`.

```{r metadata}

source("metadata-utils.R")

# Write the overall README
readme_fn <- file.path(params$METADATA_ROOT,
                       params$RELEASE_README_FILES, 
                       paste0("README_v", params$L1_VERSION, ".txt"))
if(!file.exists(readme_fn)) stop("Couldn't find ", readme_fn)
readme <- readLines(readme_fn)
readme <- gsub("[VERSION]", params$L1_VERSION, readme, fixed = TRUE)
readme <- gsub("[DATESTAMP]", params$L1_RELEASE_DATE, readme, fixed = TRUE)
readme <- gsub("[OBSERVATIONS]", n_obs, readme, fixed = TRUE)
readme <- gsub("[GIT_COMMIT]", GIT_COMMIT, readme, fixed = TRUE)
readme <- gsub("[TIMEZONE]", params$L1_DATA_TIMEZONE, readme, fixed = TRUE)
readme_outfn <- file.path(L1, basename(readme_fn))
message("Writing overall README ", readme_outfn, "...")
writeLines(readme, readme_outfn)

# Get the L1 template file
template_file <- file.path(params$METADATA_ROOT,
                           params$L1_METADATA, 
                           "L1_metadata_template.txt")
if(!file.exists(template_file)) {
    stop("Couldn't find file ", basename(template_file), " in ", params$L1_METADATA)
}
L1_metadata_template <- readLines(template_file)

col_md_for_insert <- paste(sprintf("%-15s", column_md$Column), column_md$Description)

# Get the variable metadata
var_md_for_insert <- md_variable_info(file.path(params$METADATA_ROOT,
                                                params$METADATA_VARS_TABLE))

message("Main template has ", length(L1_metadata_template), " lines")
message("Column metadata info has ", length(col_md_for_insert), " lines")
message("Variable metadata info has ", length(var_md_for_insert), " lines")

# Identify the main data directories in L1/{version}/, which are <site>_<year>
data_dirs <- list.files(L1, pattern = "^[a-zA-Z]+_[0-9]{4}$")
site_files_folder <- file.path(params$METADATA_ROOT, 
                              params$METADATA_SITE_FILES)

for(dd in data_dirs) {
    dd_full <- file.path(L1, dd)
    message("Generating metadata for ", dd_full)
    
    message("\tInserting timestamp and folder name")
    md <- gsub("[TIMESTAMP]", date(), L1_metadata_template, fixed = TRUE)
    md <- gsub("[FOLDER_NAME]", dd, md, fixed = TRUE)
    
    # Insert info on data files into metadata
    md <- md_insert_fileinfo(dd_full, md)
   
    # Insert column metadata
    col_info_pos <- grep("[COLUMN_INFO]", md, fixed = TRUE)
    md <- append(md, col_md_for_insert, after = col_info_pos)
    md <- md[-col_info_pos]
    
    # Insert NA code, time zone, and version information
    md <- md_insert_miscellany(md, 
                               NA_STRING_L1, 
                               params$L1_DATA_TIMEZONE, 
                               params$L1_VERSION)
    
    # Insert variable metadata
    var_info_pos <- grep("[VARIABLE_INFO]", md, fixed = TRUE)
    md <- append(md, var_md_for_insert, after = var_info_pos)
    md <- md[-var_info_pos]
    
    # Site information
    # Folders are <site>_<year>
    site <- strsplit(dd, "_")[[1]][1]
    md <- md_insert_siteinfo(site, site_files_folder, md)

    # Write the final metadata file
    mdfn <- paste0(dd, "_L1_v", params$L1_VERSION, "_metadata.txt")
    message("\tWriting ", mdfn, "...")
    writeLines(md, file.path(L1, dd, mdfn))
}
```

## Documentation and code

```{r docs-and-code}

ok <- file.copy(params$CODE_EXAMPLES, L1, recursive = TRUE)
if(ok) {
    message("Copied ", params$CODE_EXAMPLES, " to ", L1)
} else {
    warning("There was a problem copying ", params$CODE_EXAMPLES)
}
```

## Output summary

```{r output_summary_table}
knitr::kable(out_df)
```

Total rows written: `r n_obs`

Total NA rows written: `r n_na`

## Clean up

```{r cleanup}
#fdb_cleanup() # Close flags database
```

## Reproducibility

Git commit `r GIT_COMMIT`.

```{r reproducibility}
sessionInfo()
```
